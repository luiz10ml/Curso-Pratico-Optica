# Curso-Pratico-Optica

![Inatel](https://img.shields.io/badge/Institui√ß√£o-Inatel-blue)
![N√≠vel](https://img.shields.io/badge/N√≠vel-Gradua√ß√£o-success)
![√Årea](https://img.shields.io/badge/√Årea-Telecomunica√ß√µes-informational)

---

# üì° Curso Pr√°tico: Predistor√ß√£o Digital (DPD) com Redes Neurais

Este reposit√≥rio cont√©m o material did√°tico para implementa√ß√£o de uma **Predistor√ß√£o Digital (DPD)** utilizando Redes Neurais do tipo **MLP (Multi-Layer Perceptron)** para linearizar um **Modulador Mach-Zehnder (MZM)** em sistemas **Radio-over-Fiber (RoF)**.

---

# üìñ 1. Introdu√ß√£o e Setup

<img src="/figuras/rofDiagram.png" width="900px"> 


## üì° Representa√ß√£o F√≠sica vs. Modelo Matem√°tico

O diagrama acima apresenta **duas formas equivalentes** de representar um sistema **Radio-over-Fiber (RoF)**.

---

### üî¨ Sistema F√≠sico Real (Diagrama da Esquerda)

√Ä esquerda, temos o sistema f√≠sico completo, composto por:

- Transmissor SDR (Tx)  
- Amplificador de Pot√™ncia (PA)  
- Laser (LD)  
- Modulador Mach-Zehnder (MZM)  
- Caminho √ìptico  
- Fotodiodo (PD)  
- Receptor (Rx)  

O funcionamento ocorre da seguinte forma:

1. O transmissor gera o sinal el√©trico.
2. O sinal √© amplificado pelo PA.
3. O MZM converte o sinal el√©trico em modula√ß√£o √≥ptica.
4. O sinal √≥ptico se propaga pelo enlace.
5. O fotodiodo reconverte o sinal √≥ptico para o dom√≠nio el√©trico.

Durante esse processo surgem **n√£o-linearidades**, principalmente associadas ao MZM.  
Como consequ√™ncia, o sinal de sa√≠da n√£o √© uma c√≥pia perfeita do sinal de entrada.

---

### üìê Modelo Matem√°tico Equivalente (Diagrama da Direita)

√Ä direita, o mesmo sistema √© representado por um **modelo polinomial sem mem√≥ria**, que descreve a rela√ß√£o entre entrada e sa√≠da:

<img src="/figuras/modelo.png" width="200px"> 

Onde:

- `v_n` ‚Üí amostra de entrada  
- `z_n` ‚Üí amostra de sa√≠da  
- `h_j` ‚Üí coeficientes complexos do modelo  
- `J` ‚Üí ordem do polin√¥mio  

#### üìå O que significa "sem mem√≥ria"?

Significa que a sa√≠da no instante `n` depende apenas da entrada naquele mesmo instante.  
N√£o h√° depend√™ncia de amostras anteriores (`v_{n-1}`, `v_{n-2}`, etc.).

Se os coeficientes `h_j` forem corretamente estimados a partir de medi√ß√µes reais, esse modelo consegue reproduzir com alta fidelidade o comportamento do sistema f√≠sico completo, conforme ilustram as Figuras abaixo:

<img src="/figuras/desempenho.png" width="900px"> 


---

## üéØ Por que usar um modelo em vez do sistema f√≠sico?

Substituir o sistema f√≠sico por um modelo matem√°tico traz vantagens fundamentais, especialmente em ambiente acad√™mico:

- ‚úÖ Permite gerar amostras ilimitadas sem laborat√≥rio  
- ‚úÖ Reduz drasticamente custos (equipamentos √≥pticos s√£o caros)  
- ‚úÖ Garante reprodutibilidade total dos experimentos  
- ‚úÖ Facilita o treinamento de algoritmos de DPD  
- ‚úÖ Permite explorar diferentes n√≠veis de n√£o-linearidade alterando apenas os coeficientes  

Em outras palavras:

> O modelo substitui um sistema f√≠sico complexo por uma representa√ß√£o matem√°tica compacta, viabilizando simula√ß√µes, testes e desenvolvimento de algoritmos de forma r√°pida, controlada e acess√≠vel.

√â exatamente esse modelo que ser√° utilizado neste curso para treinar uma rede neural MLP capaz de realizar a **Predistor√ß√£o Digital (DPD)** e compensar os efeitos n√£o-lineares do modulador.

---


Prepara√ß√£o do ambiente no Google Colab:

```python
# Instala√ß√£o da biblioteca de modula√ß√£o
!pip install ModulationPy -q

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from ModulationPy import QAMModem
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from scipy.signal import welch
import os


# Early Stopping
callback_dpd = tf.keras.callbacks.EarlyStopping(
    monitor='loss',
    patience=50,
    min_delta=1e-9,
    restore_best_weights=True
)
```

# ‚öôÔ∏è 2. Teste da GPU

Prepara√ß√£o do ambiente no Google Colab:

```python
# %% Verifica√ß√£o da GPU
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  print('Connected without GPU Device')
else: 
  print('Connected with GPU Device')
```

---

# ‚öôÔ∏è 3. Par√¢metros do Sistema OFDM

| Par√¢metro | Valor | Descri√ß√£o |
|-----------|--------|-----------|
| K | 2048 | Tamanho da FFT |
| NUM_BLOCOS | 10 | Quantidade de blocos |
| MOD_ORDER | 16 | Modula√ß√£o 16-QAM |
| SNR_DB | 45 | Rela√ß√£o Sinal-Ru√≠do |
| J | 2 | Ordem da n√£o-linearidade |

```python
# --- CONFIGURA√á√ïES DO SISTEMA ---
K = 2048                                  # N√∫mero de subportadoras (Tamanho da FFT)
NUM_BLOCOS = 10                           # Quantidade de blocos OFDM para processamento
SUBPORT_ATIVAS = np.arange(-200, 201, 1)  # Espectro ocupado
MOD_ORDER = 16                            # 16-QAM
SNR_DB = 45                               # Rela√ß√£o Sinal-Ru√≠do do canal
J = 2                                     # Ordem do modelo polinomial do modulador (N√£o-linearidade)
```

---

# üß† 4. Fun√ß√µes de Apoio

```python
def suavizar_espectro(vetor_db, janela=20):
    """Aplica uma m√©dia m√≥vel robusta para deixar o gr√°fico da DEP bem suave."""
    return np.convolve(vetor_db, np.ones(janela)/janela, mode='same')

def modular_qam(bits_ou_indices, ordem):
    """Realiza a modula√ß√£o QAM e normaliza a pot√™ncia unit√°ria."""
    modem = QAMModem(ordem, bin_input=False, soft_decision=False, bin_output=False)
    simbolos = modem.modulate(bits_ou_indices)
    potencia_media = np.mean(np.abs(simbolos)**2)
    simbolos_norm = simbolos * np.sqrt(1 / potencia_media)
    return simbolos_norm, modem

def mapear_ofdm(simbolos_qam, indices_ativos, tamanho_fft):
    """Aloca os s√≠mbolos QAM nas subportadoras espec√≠ficas da FFT."""
    espectro = np.zeros(tamanho_fft, dtype=complex)
    espectro[indices_ativos] = simbolos_qam
    return espectro

def canal_awgn(sinal, snr_db, pot_referencia):
    """Adiciona ru√≠do gaussiano branco (AWGN) baseado na SNR desejada."""
    sigma2 = pot_referencia * 10**(-snr_db/10)
    ruido = np.sqrt(sigma2/2) * (np.random.randn(*sinal.shape) + 1j*np.random.randn(*sinal.shape))
    return sinal + ruido

def modelo_mzm(coeficientes, sinal_in, ordem):
    """Representa o comportamento n√£o-linear do Modulador Mach-Zehnder."""
    # Matriz onde cada coluna √© o sinal elevado a uma pot√™ncia √≠mpar (comum em RF)
    X = np.column_stack([sinal_in * np.abs(sinal_in)**k for k in range(ordem)])
    return X.dot(coeficientes)

def calcular_evm(simbolos_est, simbolos_ref):
    """Calcula o Error Vector Magnitude em porcentagem."""
    erro = simbolos_est - simbolos_ref
    return np.sqrt(np.mean(np.abs(erro)**2) / np.mean(np.abs(simbolos_ref)**2)) * 100

def calcular_mer(simbolos_est, simbolos_ref):
    """Calcula o Modulation Error Ratio em dB."""
    erro = simbolos_est - simbolos_ref
    p_sinal = np.mean(np.abs(simbolos_ref)**2)
    p_erro = np.mean(np.abs(erro)**2)
    return 10 * np.log10(p_sinal / p_erro)
```

---

# üìä 5. Carregando os Coeficientes do Modelo Polinomial

<img src="/figuras/data.png" width="900px"> 
---

## üß™ Coleta de Dados Experimentais

A figura acima mostra o setup experimental utilizado para a coleta de dados do sistema **RoF**.

O objetivo principal do experimento foi coletar dois conjuntos de amostras:

- üîπ **Sinal de entrada sem distor√ß√£o (TX Data)**  
- üîπ **Sinal de sa√≠da distorcido (RX Data)**  

O sinal transmitido pelo SDR √© aplicado ao PA e ao Modulador Mach-Zehnder (MZM), propagando-se pelo enlace √≥ptico.  
No receptor, o fotodiodo converte novamente o sinal para o dom√≠nio el√©trico, resultando em uma vers√£o distorcida do sinal original.

Esses dois sinais (entrada e sa√≠da) s√£o armazenados para posterior modelagem do sistema.

---

## ‚è±Ô∏è Alinhamento Temporal (Sincroniza√ß√£o)

Ap√≥s a coleta, as sequ√™ncias TX e RX n√£o est√£o perfeitamente alinhadas no tempo devido a:

- Atrasos do enlace
- Atrasos de hardware
- Processamento interno dos dispositivos

Para corrigir isso, √© necess√°rio realizar **sincroniza√ß√£o temporal** utilizando **correla√ß√£o cruzada** entre o sinal transmitido e o sinal recebido.

Um **preambulo conhecido** √© inserido no in√≠cio do sinal transmitido, permitindo realizar o alinhamento temporal.

Para estimar `h`, utilizamos a Equa√ß√£o Normal dos M√≠nimos Quadrados:

<img src="/figuras/coeficientes.png" width="150px"> 


Onde:

- `V^H` √© a transposta conjugada de `V`

- `h` √© o vetor estimado de coeficientes

Essa solu√ß√£o minimiza o erro quadr√°tico m√©dio entre o modelo e o sistema real.



```python
# --- GERA√á√ÉO DE DADOS E CANAL (CEN√ÅRIO SEM DPD) ---


# Link para o arquivo RAW no seu GitHub
# Substitua 'SEU_USUARIO' e 'SEU_REPOSITORIO' pelos seus dados reais
url_coef = "https://raw.githubusercontent.com/luiz10ml/Curso-Pratico-Optica/main/coeficientes/coef"


# Faz o download do arquivo para o ambiente do Colab
if not os.path.exists("coef"):
    !wget {url_coef} -O coef

# Carregamento dos dados
coef_mzm = np.fromfile("coef", dtype=np.complex64)

print(f"Coeficientes carregados com sucesso!: {coef_mzm}")

```
---
# üìä 6. Gera√ß√£o dos dados
```python
# Vetores para armazenar o sinal completo
sinal_tx_total = np.zeros(NUM_BLOCOS * K, dtype=complex)

for i in range(NUM_BLOCOS):
    p_tx_dbm = np.random.randint(-5, 16)
    p_tx_linear = 10**(p_tx_dbm/10) * 1e-3
    
    indices = np.random.randint(0, MOD_ORDER, size=len(SUBPORT_ATIVAS))
    qam_norm, _ = modular_qam(indices, MOD_ORDER)
    
    espectro_mapeado = mapear_ofdm(qam_norm, SUBPORT_ATIVAS, K)
    sinal_tempo = np.fft.ifft(espectro_mapeado) * np.sqrt(K)
    
    escala = np.sqrt(p_tx_linear / np.mean(np.abs(sinal_tempo)**2))
    sinal_tx_total[i*K : (i+1)*K] = sinal_tempo * escala

# Passagem pelo Modulador N√£o-Linear (MZM) e Canal
sinal_distorcido = modelo_mzm(coef_mzm, sinal_tx_total, J)
sinal_recebido = canal_awgn(sinal_distorcido, SNR_DB, np.mean(np.abs(sinal_tx_total)**2))
```

---

# ü§ñ 7. Arquitetura e Treinamento da Rede Neural (DPD)

<img src="/figuras/train.png" width="900px"> 


Ap√≥s obter o par de sinais **entrada sem distor√ß√£o** e **sa√≠da distorcida** (j√° sincronizados no tempo), treinamos uma rede neural do tipo **MLP (Multi-Layer Perceptron)** para aprender a opera√ß√£o inversa da distor√ß√£o.

A ideia √© simples:

- **Entrada da MLP (features):** amostras do sinal **distorcido** no receptor  
- **Sa√≠da desejada (labels):** amostras do sinal **original sem distor√ß√£o** no transmissor

Em outras palavras, a MLP recebe o sinal ‚Äúestragado‚Äù (distorcido) e aprende a estimar qual era o sinal original antes do enlace RoF.

Como os sinais s√£o complexos, o processamento √© feito separando:

- Parte real (I)
- Parte imagin√°ria (Q)

Assim, cada amostra complexa vira um vetor real de 2 dimens√µes:


### üéØ Fun√ß√£o de Custo (Erro Quadr√°tico M√©dio)

Os coeficientes (pesos) da MLP s√£o ajustados minimizando o **Erro Quadr√°tico M√©dio (MSE)** entre:

- o **label** (sinal original sem distor√ß√£o), e
- a **estimativa produzida pela MLP** na sa√≠da

A fun√ß√£o custo usada no treinamento √© o erro

```math
J_e(\mathbf{w}) = \frac{1}{N}\left\|\mathbf{v} - \hat{\mathbf{v}}\right\|^2
```


```python
X_train = np.c_[sinal_recebido.real, sinal_recebido.imag]
y_train = np.c_[sinal_tx_total.real, sinal_tx_total.imag]

model_dpd = Sequential([
    Dense(2048, activation='relu', input_shape=(2,)),
    Dense(1024, activation='relu'),
    Dense(2)
])

model_dpd.compile(optimizer='adam', loss='mse')

model_dpd.fit(
    X_train,
    y_train,
    epochs=200,
    batch_size=K,
    verbose=2,
    callbacks=[callback_dpd]
)
```

---

# üèÅ 8. Teste e Valida√ß√£o

```python
print("\n--- Avaliando Performance ---")
p_teste_dbm = 10 
p_teste_lin = 10**(p_teste_dbm/10) * 1e-3

indices_teste = np.random.randint(0, MOD_ORDER, size=len(SUBPORT_ATIVAS))
qam_teste, modem_obj = modular_qam(indices_teste, MOD_ORDER)
sinal_ofdm_teste = np.fft.ifft(mapear_ofdm(qam_teste, SUBPORT_ATIVAS, K)) * np.sqrt(K)
sinal_ofdm_teste *= np.sqrt(p_teste_lin / np.mean(np.abs(sinal_ofdm_teste)**2))

# 1. Caso SEM DPD
saida_sem_dpd = modelo_mzm(coef_mzm, sinal_ofdm_teste, J)
energia_saida = np.mean(abs(saida_sem_dpd)**2)
saida_sem_dpd = saida_sem_dpd*np.sqrt(np.mean(abs(sinal_ofdm_teste)**2)/energia_saida)

# 2. Caso COM DPD
sinal_entrada_mlp = np.c_[sinal_ofdm_teste.real, sinal_ofdm_teste.imag]
sinal_pre_distorcido_raw = model_dpd.predict(sinal_entrada_mlp, verbose=0)
sinal_pre_distorcido = sinal_pre_distorcido_raw[:,0] + 1j*sinal_pre_distorcido_raw[:,1]
saida_com_dpd = modelo_mzm(coef_mzm, sinal_pre_distorcido, J)

# --- DEMODULA√á√ÉO E C√ÅLCULO DE M√âTRICAS ---
def processar_receptor(sinal_rx, ref_qam):
    rx_f = np.fft.fft(sinal_rx) / np.sqrt(K)
    qam_rx = rx_f[SUBPORT_ATIVAS]
    qam_rx *= np.sqrt(np.mean(np.abs(ref_qam)**2) / np.mean(np.abs(qam_rx)**2))
    evm_val = calcular_evm(qam_rx, ref_qam)
    mer_val = calcular_mer(qam_rx, ref_qam)
    return qam_rx, evm_val, mer_val

qam_sem, evm_sem, mer_sem = processar_receptor(saida_sem_dpd, qam_teste)
qam_com, evm_com, mer_com = processar_receptor(saida_com_dpd, qam_teste)
```

---
# üèÅ 9. An√°lise Espectral

```python
f_ref, p_ref = welch(sinal_ofdm_teste, fs=1.0, window='hann', nperseg=K, return_onesided=False)
f_sem, p_sem = welch(saida_sem_dpd, fs=1.0, window='hann', nperseg=K, return_onesided=False)
f_com, p_com = welch(saida_com_dpd, fs=1.0, window='hann', nperseg=K, return_onesided=False)

# Suaviza√ß√£o e centraliza√ß√£o (Janela aumentada para suavizar mais)
db_ref = np.fft.fftshift(suavizar_espectro(10*np.log10(p_ref + 1e-12), janela=41))
db_sem = np.fft.fftshift(suavizar_espectro(10*np.log10(p_sem + 1e-12), janela=41))
db_com = np.fft.fftshift(suavizar_espectro(10*np.log10(p_com + 1e-12), janela=41))
f_plot = np.fft.fftshift(f_sem)
```

---
# üèÅ 10. Plotando os Resultados

```python
plt.figure(figsize=(12, 10))

# Plot 1: Constela√ß√£o Sem DPD (Topo Esquerda)
plt.subplot(221)
plt.scatter(qam_sem.real, qam_sem.imag, s=5, label=f'Sem DPD ({evm_sem:.1f}%)')
plt.title("Constela√ß√£o: Sem DPD")
plt.grid(); plt.legend(loc='upper right')

# Plot 2: Constela√ß√£o Com DPD (Topo Direita)
plt.subplot(222)
plt.scatter(qam_com.real, qam_com.imag, s=5, color='green', label=f'Com DPD ({evm_com:.1f}%)')
plt.title("Constela√ß√£o: Com MLP-DPD")
plt.grid(); plt.legend(loc='upper right')

# Plot 3: Densidade Espectral de Pot√™ncia (Base - Ocupando as duas colunas)
plt.subplot(212)
plt.plot(f_plot, db_ref, color='black', label='Ideal (Refer√™ncia)', linestyle='--', alpha=0.6)
plt.plot(f_plot, db_sem, label='Sem DPD (Distorcido)', alpha=0.8)
plt.plot(f_plot, db_com, label='Com MLP-DPD (Linearizado)', color='green', linewidth=2)
plt.title("Densidade Espectral de Pot√™ncia (Suavizada)")
plt.xlabel("Frequ√™ncia Normalizada")
plt.ylabel("Magnitude (dB)")
plt.ylim(np.max(db_ref)-60, np.max(db_ref)+5)
plt.grid(); plt.legend()

plt.tight_layout()
plt.show()

print(f"RESULTADO FINAL ({p_teste_dbm} dBm):")
print(f"Sem DPD -> MER: {mer_sem:.2f} dB | EVM: {evm_sem:.2f}%")
print(f"Com DPD -> MER: {mer_com:.2f} dB | EVM: {evm_com:.2f}%")
```

---

# üöÄ Como usar

1. Abra o Google Colab  
2. Copie os blocos em c√©lulas separadas  
3. Execute em ordem  

---

> üí° **Exercicios para casa:**  
Altere o n√∫mero de neur√¥nios ou trocar `relu` por `tanh`, `elu`, `selu`, `LeakyReLU` e observar o impacto no desempenho.


## üìö Refer√™ncias Bibliogr√°ficas

[1] Luiz. A. M. Pereira; Luciano. L. Mendes; Mitchell A. Cox; Arismar Cerqueira S. Jr.. Open dataset initiative for machine learning-based linearization in analog radio over fiber systems. Optics Communications, v. 590, p. 131949, 2025. ISSN 0030-4018. DOI: 10.1016/j.optcom.2025.131949. Dispon√≠vel em: https://www.sciencedirect.com/science/article/pii/S0030401825004778




Prof. Dr. Luiz Augusto Melo Pereira

luiz.melo@inatel.br